{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found labels: ['.DS_Store', 'Aamir', 'Ajay', 'Akshay', 'Alia', 'Amitabh', 'Deepika', 'Disha', 'Farhan', 'Ileana']\n",
      "Unique image shapes loaded: {(100, 100)}\n",
      "Loaded 450 images with labels\n",
      "\n",
      "Displaying 10 sample face images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 16:00:20.522 python3.10[45348:1145419] not in fullscreen state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 270 samples\n",
      "Testing set size: 180 samples\n",
      "\n",
      "Evaluating with PCA components: 20\n",
      "Accuracy: 0.4111\n",
      "\n",
      "Evaluating with PCA components: 30\n",
      "Accuracy: 0.4000\n",
      "\n",
      "Evaluating with PCA components: 40\n",
      "Accuracy: 0.1722\n",
      "\n",
      "Evaluating with PCA components: 50\n",
      "Accuracy: 0.4611\n",
      "\n",
      "Evaluating with PCA components: 60\n",
      "Accuracy: 0.6222\n",
      "\n",
      "Evaluating with PCA components: 70\n",
      "Accuracy: 0.2889\n",
      "\n",
      "Evaluating with PCA components: 80\n",
      "Accuracy: 0.4889\n",
      "\n",
      "Summary of accuracies for different PCA component values:\n",
      "PCA components: 20 - Accuracy: 0.4111\n",
      "PCA components: 30 - Accuracy: 0.4000\n",
      "PCA components: 40 - Accuracy: 0.1722\n",
      "PCA components: 50 - Accuracy: 0.4611\n",
      "PCA components: 60 - Accuracy: 0.6222\n",
      "PCA components: 70 - Accuracy: 0.2889\n",
      "PCA components: 80 - Accuracy: 0.4889\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "def load_face_database(path, target_size=(100, 100)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = sorted(os.listdir(path))\n",
    "    print(f\"Found labels: {label_names}\")\n",
    "    for label in label_names:\n",
    "        label_path = os.path.join(path, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        for filename in os.listdir(label_path):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.pgm')):\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    # Resize to fixed size (important!)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    images.append(img_resized)\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Warning: failed to load image {img_path}\")\n",
    "    # Check all images have the same shape before converting to np.array\n",
    "    unique_shapes = set(img.shape for img in images)\n",
    "    print(f\"Unique image shapes loaded: {unique_shapes}\")\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(f\"Loaded {len(images)} images with labels\")\n",
    "    return images, labels\n",
    "\n",
    "def display_sample_faces(images, labels, num_samples=10):\n",
    "    print(f\"\\nDisplaying {num_samples} sample face images...\")\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        cv2.imshow(f\"Face - {label}\", img)\n",
    "        cv2.waitKey(1000)  # Display each face for 1000 ms (1 second)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def evaluate_model_with_different_k(face_db, labels, k_values, test_size=0.4, random_state=42):\n",
    "    # Flatten images for PCA input\n",
    "    X = np.array([img.flatten() for img in face_db])\n",
    "    # Encode labels as integers\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    \n",
    "    # Split dataset into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "    print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    # Suppress convergence warnings for cleaner output\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"\\nEvaluating with PCA components: {k}\")\n",
    "        \n",
    "        # Apply PCA with k components\n",
    "        pca = PCA(n_components=k, whiten=True, random_state=random_state)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        \n",
    "        # Train a simple ANN (MLPClassifier) on PCA features\n",
    "        ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, early_stopping=True, random_state=random_state)\n",
    "        ann.fit(X_train_pca, y_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred = ann.predict(X_test_pca)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    # Return all results and models of last run\n",
    "    return k_values, accuracies, pca, ann, X_test, y_test, le\n",
    "\n",
    "# ---- Main Execution ----\n",
    "\n",
    "dataset_path = 'dataset/att_faces'  \n",
    "\n",
    "face_db, labels = load_face_database(dataset_path)\n",
    "\n",
    "if len(face_db) == 0:\n",
    "    print(\"No images loaded! Please check your dataset path and contents.\")\n",
    "else:\n",
    "    # Show some sample faces with labels\n",
    "    display_sample_faces(face_db, labels, num_samples=10)\n",
    "    \n",
    "    # Evaluate model with different PCA component values\n",
    "    k_values = list(range(20, 81, 10))  # 20, 30, ..., 80\n",
    "    k_values, accuracies, pca_model, ann_model, X_test, y_test, label_encoder = evaluate_model_with_different_k(face_db, labels, k_values)\n",
    "    \n",
    "    print(\"\\nSummary of accuracies for different PCA component values:\")\n",
    "    for k, acc in zip(k_values, accuracies):\n",
    "        print(f\"PCA components: {k} - Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
